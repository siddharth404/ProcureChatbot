<<<<<<< HEAD
## üöÄ Quickstart

### 1Ô∏è‚É£ Clone and Install Dependencies
```bash
git clone https://github.com/<your-username>/ProcureCopilot.git
cd ProcureCopilot
pip install -r requirements.txt
```

---

### 2Ô∏è‚É£ Configure Environment Variables

Create a `.env` file or export variables directly:

```bash
# Provider: openai (default) | groq | gemini
export PROVIDER=openai

# OpenAI
export OPENAI_API_KEY="sk-..."
export OPENAI_MODEL="gpt-4o-mini"

# Groq (optional)
export GROQ_API_KEY="gsk_..."
export GROQ_MODEL="llama-3.1-70b-versatile"

# Gemini (optional)
export GEMINI_API_KEY="..."
export GEMINI_MODEL="gemini-1.5-flash"

# Search
export SEARCH_PROVIDER="ddg"   # or "serpapi"
export SERPAPI_KEY=""           # optional, if using SerpAPI

# RAG Settings
export EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
export CHUNK_SIZE=1200
export CHUNK_OVERLAP=200
export TOP_K=4
```

---

## üß∞ Running Locally

```bash
streamlit run app.py
=======
# ü¶∫ ProcureCopilot ‚Äî RAG + Live Web Search Chatbot for Infrastructure Tenders

<p align="center">
  <a href="https://streamlit.io/cloud"><img alt="Deploy on Streamlit" src="https://img.shields.io/badge/Deploy-Streamlit%20Cloud-brightgreen"></a>
  <img alt="Python" src="https://img.shields.io/badge/Python-3.10%2B-blue">
  <img alt="License" src="https://img.shields.io/badge/License-MIT-informational">
  <img alt="RAG" src="https://img.shields.io/badge/RAG-FAISS%20%2B%20SentenceTransformer-green">
  <img alt="LLMs" src="https://img.shields.io/badge/LLMs-OpenAI%20%7C%20Groq%20%7C%20Gemini-orange">
</p>

---

### üì∏ Screenshot
> Replace `docs/screenshot.png` with your app screenshot after deployment.

<p align="center">
  <img src="docs/screenshot.png" alt="ProcureCopilot UI" width="800"/>
</p>

---

## üß† Project Overview

**ProcureCopilot** is an AI-powered assistant designed for **infrastructure tender analysis** (EPC / contracting domain).  
It helps engineers, managers, and analysts **understand tender documents**, extract eligibility criteria, and monitor corrigenda ‚Äî all through natural language queries.

### üíº Use Case
Indian EPC firms often deal with 100+ page tender documents (NIT, GCC/SCC, BOQ, addenda).  
ProcureCopilot lets them:
- Upload PDF or TXT tender documents
- Ask queries like ‚ÄúWhat is the turnover requirement?‚Äù or ‚ÄúList EMD and bid validity period.‚Äù
- Perform **live web searches** for corrigenda or clarifications.
- Choose between **Concise** and **Detailed** response styles.

---

## üß© Key Features

| Feature | Description |
|----------|--------------|
| **RAG Integration** | Ingest and index PDFs using SentenceTransformer embeddings + FAISS for retrieval. |
| **Live Web Search** | Queries live data (DuckDuckGo or SerpAPI). Useful for corrigenda, updates, or bidder clarifications. |
| **Concise/Detailed Modes** | UI toggle to control verbosity of responses. |
| **Multi-LLM Support** | Works with OpenAI (default), Groq, or Gemini with a single environment variable change. |
| **Error Handling** | Graceful fallbacks, clear user messages. |
| **Streamlit UI** | Intuitive and responsive interface for document upload and Q&A. |

---

## ‚öôÔ∏è Architecture Overview

```bash
ProcureCopilot/
‚îú‚îÄ‚îÄ app.py                     # Streamlit UI, user interactions
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.py              # Centralized configuration and env vars
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ llm.py                 # Unified LLM adapter (OpenAI, Groq, Gemini)
‚îÇ   ‚îî‚îÄ‚îÄ embeddings.py          # SentenceTransformer-based embedding class
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ rag.py                 # RAG engine: PDF extraction, chunking, FAISS
‚îÇ   ‚îú‚îÄ‚îÄ search.py              # DuckDuckGo & SerpAPI-based live search
‚îÇ   ‚îî‚îÄ‚îÄ prompting.py           # Prompt construction for Concise/Detailed modes
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ screenshot.png         # Placeholder for app UI screenshot
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
>>>>>>> 028b04d69e262d2a64029b6b6e4f666117ea4178
```
üöÄ Quickstart
1Ô∏è‚É£ Clone and Install Dependencies
git clone https://github.com/<your-username>/ProcureCopilot.git
cd ProcureCopilot
pip install -r requirements.txt

<<<<<<< HEAD
Visit üëâ `http://localhost:8501` in your browser.

**Steps:**
1. Upload one or more **tender PDFs or TXT files**.  
2. Click **üîß Build Index** (it will chunk & embed text).  
3. Type a query like:
   - ‚ÄúSummarize eligibility criteria.‚Äù
   - ‚ÄúWhat is the EMD and bid validity period?‚Äù
4. (Optional) Toggle **Use Web Search** to pull live results.  
5. Switch **Response Mode** to ‚ÄúConcise‚Äù or ‚ÄúDetailed‚Äù as needed.

---

## ‚òÅÔ∏è Deploying on Streamlit Cloud

1. Push your repo to GitHub.
2. Go to [Streamlit Cloud](https://share.streamlit.io).
3. Create a **New App** ‚Üí Select your GitHub repo.  
   - **Main file:** `app.py`  
   - **Branch:** `main`  
4. In **Secrets**, add:
   ```
   OPENAI_API_KEY = "sk-..."
   SERPAPI_KEY = ""
   GROQ_API_KEY = ""
   GEMINI_API_KEY = ""
   ```
5. Click **Deploy** üöÄ  
6. Copy your public URL (e.g. `https://yourname-procurecopilot.streamlit.app`)  
   ‚Üí Add it in your presentation or submission.

---

## üßÆ How It Works

| Step | Description |
|------|--------------|
| **1. Ingestion** | PDFs are parsed using `pypdf` ‚Üí text cleaned & chunked. |
| **2. Embedding** | Chunks embedded via `SentenceTransformer`. |
| **3. Indexing** | FAISS vector store for similarity search. |
| **4. Retrieval** | Top-K chunks retrieved based on query. |
| **5. Augmentation** | LLM combines retrieved + web context ‚Üí final answer. |
| **6. Output Modes** | Prompt builder formats response as Concise or Detailed. |

---

## üß™ Example Queries

| Query | Expected Behavior |
|--------|-------------------|
| ‚ÄúList the eligibility and turnover criteria.‚Äù | Extracts relevant clauses from local PDF. |
| ‚ÄúWhat is the EMD amount and bid validity?‚Äù | Returns numeric details from the tender. |
| ‚ÄúHas any corrigendum been published recently?‚Äù | Triggers **web search** for latest results. |
| ‚ÄúSummarize all technical requirements.‚Äù | Detailed structured response with bullet points. |

---

## üîß Configuration Parameters

| Variable | Default | Description |
|-----------|----------|-------------|
| `CHUNK_SIZE` | 1200 | Token length per text chunk |
| `CHUNK_OVERLAP` | 200 | Overlap between chunks |
| `TOP_K` | 4 | Retrieved chunks count |
| `SEARCH_PROVIDER` | ddg | `ddg` or `serpapi` |
| `PROVIDER` | openai | LLM provider: openai, groq, gemini |

---

## üß© Technology Stack

| Layer | Library |
|--------|----------|
| **Frontend / UI** | Streamlit |
| **LLM API** | OpenAI / Groq / Gemini |
| **Embeddings** | Sentence-Transformers |
| **Vector Search** | FAISS |
| **PDF Parsing** | PyPDF |
| **Web Search** | DuckDuckGo / SerpAPI |

---

## üß± Project Strengths

‚úÖ Modular and extensible design  
‚úÖ Streamlit-ready for instant deployment  
‚úÖ Secure key handling (env vars only)  
‚úÖ RAG + Web Search dual mode  
‚úÖ Domain-specific tender analysis focus  
‚úÖ Multi-provider support (OpenAI, Groq, Gemini)

---

## üíª Requirements

```
=======
2Ô∏è‚É£ Configure Environment Variables

Create a .env file or export variables directly:

# Provider: openai (default) | groq | gemini
export PROVIDER=openai

# OpenAI
export OPENAI_API_KEY="sk-..."
export OPENAI_MODEL="gpt-4o-mini"

# Groq (optional)
export GROQ_API_KEY="gsk_..."
export GROQ_MODEL="llama-3.1-70b-versatile"

# Gemini (optional)
export GEMINI_API_KEY="..."
export GEMINI_MODEL="gemini-1.5-flash"

# Search
export SEARCH_PROVIDER="ddg"   # or "serpapi"
export SERPAPI_KEY=""           # optional, if using SerpAPI

# RAG Settings
export EMBEDDING_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"
export CHUNK_SIZE=1200
export CHUNK_OVERLAP=200
export TOP_K=4

üß∞ Running Locally
streamlit run app.py


Visit üëâ http://localhost:8501 in your browser.

Steps:

Upload one or more tender PDFs or TXT files.

Click üîß Build Index (it will chunk & embed text).

Type a query like:

‚ÄúSummarize eligibility criteria.‚Äù

‚ÄúWhat is the EMD and bid validity period?‚Äù

(Optional) Toggle Use Web Search to pull live results.

Switch Response Mode to ‚ÄúConcise‚Äù or ‚ÄúDetailed‚Äù as needed.

‚òÅÔ∏è Deploying on Streamlit Cloud

Push your repo to GitHub.

Go to Streamlit Cloud
.

Create a New App ‚Üí Select your GitHub repo.

Main file: app.py

Branch: main

In Secrets, add:

OPENAI_API_KEY = "sk-..."
SERPAPI_KEY = ""
GROQ_API_KEY = ""
GEMINI_API_KEY = ""


Click Deploy üöÄ

Copy your public URL (e.g. https://yourname-procurecopilot.streamlit.app)
‚Üí Add it in your presentation or submission.

üßÆ How It Works
Step	Description
1. Ingestion	PDFs are parsed using pypdf ‚Üí text cleaned & chunked.
2. Embedding	Chunks embedded via SentenceTransformer.
3. Indexing	FAISS vector store for similarity search.
4. Retrieval	Top-K chunks retrieved based on query.
5. Augmentation	LLM combines retrieved + web context ‚Üí final answer.
6. Output Modes	Prompt builder formats response as Concise or Detailed.
üß™ Example Queries
Query	Expected Behavior
‚ÄúList the eligibility and turnover criteria.‚Äù	Extracts relevant clauses from local PDF.
‚ÄúWhat is the EMD amount and bid validity?‚Äù	Returns numeric details from the tender.
‚ÄúHas any corrigendum been published recently?‚Äù	Triggers web search for latest results.
‚ÄúSummarize all technical requirements.‚Äù	Detailed structured response with bullet points.
üîß Configuration Parameters
Variable	Default	Description
CHUNK_SIZE	1200	Token length per text chunk
CHUNK_OVERLAP	200	Overlap between chunks
TOP_K	4	Retrieved chunks count
SEARCH_PROVIDER	ddg	ddg or serpapi
PROVIDER	openai	LLM provider: openai, groq, gemini
üß© Technology Stack
Layer	Library
Frontend / UI	Streamlit
LLM API	OpenAI / Groq / Gemini
Embeddings	Sentence-Transformers
Vector Search	FAISS
PDF Parsing	PyPDF
Web Search	DuckDuckGo / SerpAPI
üß± Project Strengths

‚úÖ Modular and extensible design
‚úÖ Streamlit-ready for instant deployment
‚úÖ Secure key handling (env vars only)
‚úÖ RAG + Web Search dual mode
‚úÖ Domain-specific tender analysis focus
‚úÖ Multi-provider support (OpenAI, Groq, Gemini)

üíª Requirements
>>>>>>> 028b04d69e262d2a64029b6b6e4f666117ea4178
streamlit==1.37.0
openai>=1.30.0
sentence-transformers>=3.0.0
faiss-cpu>=1.8.0
pypdf>=4.3.1
duckduckgo-search>=6.2.11
serpapi>=0.1.5
groq>=0.9.0
google-generativeai>=0.7.0
Pillow>=10.4.0
<<<<<<< HEAD
```

---

## üåç Example Deployment (Preview)

**Live App:**  
> _(Replace with your deployed Streamlit Cloud URL)_  
`https://<your-username>-procurecopilot.streamlit.app`

---

## üßæ License

This project is licensed under the [MIT License](LICENSE).

```
MIT License ¬© 2025 Siddharth Kaushik  
Developed under NeoStats AI Engineer Case Study
```

---

## ü§ù Contributing

Contributions are welcome!  
Please fork this repository and submit a pull request for improvements or bug fixes.

---

## üë§ Author

**Siddharth Kaushik**  
M.Sc. Data Science & Management ‚Äî IIT Ropar √ó IIM Amritsar  
üìß [Email me](mailto:siddharth.kaushik@example.com)

---

<p align="center">Built with ‚ù§Ô∏è using Streamlit, FAISS, and modern LLMs.</p>
=======

üåç Example Deployment (Preview)

Live App:

(Replace with your deployed Streamlit Cloud URL)
https://<your-username>-procurecopilot.streamlit.app

üßæ License

This project is licensed under the MIT License
.

MIT License ¬© 2025 Siddharth Kaushik  
Developed under NeoStats AI Engineer Case Study

ü§ù Contributing

Contributions are welcome!
Please fork this repository and submit a pull request for improvements or bug fixes.

üë§ Author

Siddharth Kaushik
M.Sc. Data Science & Management ‚Äî IIT Ropar √ó IIM Amritsar
üìß Email me

<p align="center">Built with ‚ù§Ô∏è using Streamlit, FAISS, and modern LLMs.</p> ```
>>>>>>> 028b04d69e262d2a64029b6b6e4f666117ea4178
